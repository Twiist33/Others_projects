elastic_metrics <- eval_glmnet_model(X_train, y_train, X_test, y_test, alpha_val = 0.5, model_name = "Elastic Net")
results <- bind_rows(lm_metrics, ridge_metrics, lasso_metrics, elastic_metrics)
print(results)
# Chargement des donn√©es initiales contenant uniquement des donn√©es num√©riques
# Loading initial data containing only numerical data
data <- read_delim("dataset_24_25/players_data_light-2024_2025.csv", delim = ",")
# Nettoyage des noms de colonnes / Cleaning up column names
names(data) <- make.names(names(data), unique = TRUE)
# Exclure les gardiens / Exclude goalkeepers
data <- data %>% filter(Pos != "GK")
# Remplacer les NA dans les colonnes num√©riques par 0 / Replace NA in numeric columns with 0
data <- data %>%
mutate(across(where(is.numeric), ~replace_na(.x, 0)))
# Colonnes num√©riques √† utiliser sauf exclusions / Numerical columns to be used unless excluded
cols_to_exclude <- c("Rk", "Age", "Born", "G.A", "G.PK", "G.A.PK", "G.Sh", "G.xG","PK","np.G.xG", "G.SoT", "PK_stats_shooting")
num_cols <- data %>%
select(where(is.numeric)) %>%
select(-any_of(cols_to_exclude)) %>%
colnames()
# Cr√©er le jeu de donn√©es pour le mod√®le / Create the dataset for the model
data_model <- data %>%
select(Gls, all_of(num_cols)) %>%
filter(!is.na(Gls))
# Cr√©er le mod√®le / Create the model
model <- lm(Gls ~ ., data = data_model)
# Pr√©parer les donn√©es pour pr√©diction (m√™me structure que data_model sans Gls)
# Prediction for the entire dataset (same structure as data_model without Gls)
predict_data <- data %>% select(all_of(num_cols))
# Cr√©er un nouveau dataset avec les infos utiles + pr√©diction
# Create a new dataset with useful information + prediction
data_with_preds <- data %>%
mutate(Gls_pred_linear = predict(model, newdata = predict_data),     # Pr√©diction brute / Raw prediction
Gls_pred_linear = round(Gls_pred_linear, 2)) %>%                     # Pr√©diction arrondie / Rounded prediction
select(Player, Nation, Pos, Squad, Gls, Gls_pred_linear)                    # Colonnes √† conserver / Selected columns
# üëÄ Afficher les premi√®res lignes / Display first rows
head(data_with_preds)
add_glmnet_prediction <- function(data_with_preds, data, y_var, x_vars, alpha_val, pred_col_name, seed = 123) {
# üéØ Variable cible / Target variable
y <- data[[y_var]]
# üéØ Variables explicatives sous forme de matrice / Explanatory variables as matrix
X <- data %>% select(all_of(x_vars)) %>% as.matrix()
# üîç S√©lection du lambda optimal par validation crois√©e / Cross-validation to find optimal lambda
set.seed(seed)  # Pour reproductibilit√© / For reproducibility
cv_model <- cv.glmnet(X, y, alpha = alpha_val)
# üîß Lambda optimal / Optimal lambda
best_lambda <- cv_model$lambda.min
cat("Lambda optimal pour", pred_col_name, ":", best_lambda, "\n")
# üìä R√©entra√Ænement du mod√®le avec le meilleur lambda / Retrain model with best lambda
best_model <- glmnet(X, y, alpha = alpha_val, lambda = best_lambda)
# üì§ Pr√©dictions sous forme de vecteur et arrondi / Predictions as numeric vector, rounded
predictions <- predict(best_model, newx = X) %>%
as.numeric() %>%
round(2)
# ‚ûï Ajout des pr√©dictions au dataset / Add predictions to the dataset
data_with_preds[[pred_col_name]] <- predictions
# üîÅ Retourner le nouveau tableau enrichi / Return the updated dataset
return(data_with_preds)
}
# ‚ûï Ajouter les pr√©dictions Ridge / Add Ridge predictions
data_with_preds <- add_glmnet_prediction(
data_with_preds = data_with_preds,
data = data,
y_var = "Gls",              # Nom de la variable cible / Target variable name
x_vars = num_cols,          # Liste des variables explicatives / List of explanatory variables
alpha_val = 0,              # alpha = 0 ‚Üí Ridge
pred_col_name = "Gls_pred_ridge"
)
# ‚ûï Ajouter les pr√©dictions Lasso / Add Lasso predictions
data_with_preds <- add_glmnet_prediction(
data_with_preds,
data,
"Gls",
num_cols,
alpha_val = 1,              # alpha = 1 ‚Üí Lasso
pred_col_name = "Gls_pred_lasso"
)
# ‚ûï Ajouter les pr√©dictions Elastic Net / Add Elastic Net predictions
data_with_preds <- add_glmnet_prediction(
data_with_preds,
data,
"Gls",
num_cols,
alpha_val = 0.5,            # alpha = 0.5 ‚Üí Elastic Net (mix Ridge + Lasso)
pred_col_name = "Gls_pred_elastic"
)
# üëÄ Afficher les premi√®res lignes / Display first rows
head(data_with_preds)
# üìä Calcul des erreurs pour chaque mod√®le / Error calculation for each model
# Mod√®le lin√©aire / Linear Model
mae_linear <- mae(data_with_preds$Gls, data_with_preds$Gls_pred_linear)
rmse_linear <- rmse(data_with_preds$Gls, data_with_preds$Gls_pred_linear)
r2_linear <- R2(data_with_preds$Gls_pred_linear, data_with_preds$Gls)
# R√©gression Ridge / Ridge Regression
mae_ridge <- mae(data_with_preds$Gls, data_with_preds$Gls_pred_ridge)
rmse_ridge <- rmse(data_with_preds$Gls, data_with_preds$Gls_pred_ridge)
r2_ridge <- R2(data_with_preds$Gls_pred_ridge, data_with_preds$Gls)
# R√©gression Lasso / Lasso Regression
mae_lasso <- mae(data_with_preds$Gls, data_with_preds$Gls_pred_lasso)
rmse_lasso <- rmse(data_with_preds$Gls, data_with_preds$Gls_pred_lasso)
r2_lasso <- R2(data_with_preds$Gls_pred_lasso, data_with_preds$Gls)
# R√©gression Elastic Net / Elastic Net Regression
mae_elastic <- mae(data_with_preds$Gls, data_with_preds$Gls_pred_elastic)
rmse_elastic <- rmse(data_with_preds$Gls, data_with_preds$Gls_pred_elastic)
r2_elastic <- R2(data_with_preds$Gls_pred_elastic, data_with_preds$Gls)
# üßæ R√©sum√© des performances / Summary table
performance_comparison <- data.frame(
Mod√®le = c("Lin√©aire", "Ridge", "Lasso", "Elastic Net"),
MAE = c(mae_linear, mae_ridge, mae_lasso, mae_elastic),
RMSE = c(rmse_linear, rmse_ridge, rmse_lasso, rmse_elastic),
R2 = c(r2_linear, r2_ridge, r2_lasso, r2_elastic)
)
# üëÄ Affichage du tableau de comparaison / Display comparison table
print(performance_comparison)
# üßæ R√©utiliser ou cr√©er le tableau de performances / Reuse or create the performance chart
performance_comparison <- data.frame(
Mod√®le = c("Lin√©aire", "Ridge", "Lasso", "Elastic Net"),
MAE = c(mae_linear, mae_ridge, mae_lasso, mae_elastic),
RMSE = c(rmse_linear, rmse_ridge, rmse_lasso, rmse_elastic),
R2 = c(r2_linear, r2_ridge, r2_lasso, r2_elastic)
)
# üìê Convertir en format long pour ggplot2 / Convert to long format for ggplot2
performance_long <- performance_comparison %>%
pivot_longer(cols = c(MAE, RMSE, R2), names_to = "M√©trique", values_to = "Valeur")
# üìä Graphique comparatif / Comparative performance plot
ggplot(performance_long, aes(x = Mod√®le, y = Valeur, fill = Mod√®le)) +
geom_col(position = "dodge") +
facet_wrap(~ M√©trique, scales = "free_y") +
labs(title = "Comparaison des performances des mod√®les / Model performance comparison",
x = "Mod√®le / Models",
y = "Valeur de la m√©trique / Metric value") +
theme_minimal() +
theme(legend.position = "none",
text = element_text(size = 8))
set.seed(42)  # Reproductibilit√© / Reproducibility
train_index <- createDataPartition(data$Gls, p = 0.8, list = FALSE)
train_data <- data[train_index, ]
test_data  <- data[-train_index, ]
# Variables explicatives / Features matrix
X_train <- train_data %>% select(all_of(num_cols)) %>% as.matrix()
X_test  <- test_data %>% select(all_of(num_cols)) %>% as.matrix()
# Cible / Target
y_train <- train_data$Gls
y_test  <- test_data$Gls
eval_glmnet_model <- function(X_train, y_train, X_test, y_test, alpha_val, model_name) {
set.seed(123)
cv_model <- cv.glmnet(X_train, y_train, alpha = alpha_val)
best_lambda <- cv_model$lambda.min
model <- glmnet(X_train, y_train, alpha = alpha_val, lambda = best_lambda)
preds <- predict(model, newx = X_test) %>% as.numeric()
data.frame(
Mod√®le = model_name,
MAE = mae(y_test, preds),
RMSE = rmse(y_test, preds),
R2 = R2(preds, y_test)
)
}
# Mod√®le lin√©aire / Linear Model
lm_model <- lm(Gls ~ ., data = train_data %>% select(Gls, all_of(num_cols)))
lm_preds <- predict(lm_model, newdata = test_data)
lm_metrics <- data.frame(
Mod√®le = "Lin√©aire",
MAE = mae(y_test, lm_preds),
RMSE = rmse(y_test, lm_preds),
R2 = R2(lm_preds, y_test)
)
# Mod√®les p√©nalis√©s / Penalized models
ridge_metrics  <- eval_glmnet_model(X_train, y_train, X_test, y_test, alpha_val = 0, model_name = "Ridge")
lasso_metrics  <- eval_glmnet_model(X_train, y_train, X_test, y_test, alpha_val = 1, model_name = "Lasso")
elastic_metrics <- eval_glmnet_model(X_train, y_train, X_test, y_test, alpha_val = 0.5, model_name = "Elastic Net")
# On calcule les r√©sultats / We calculate the results
results <- bind_rows(lm_metrics, ridge_metrics, lasso_metrics, elastic_metrics)
print(results)
# Transformation en format long / Long format for plotting
results_long <- results %>%
pivot_longer(cols = c(MAE, RMSE, R2), names_to = "M√©trique", values_to = "Valeur")
# üìä Comparaison visuelle des mod√®les / Visual comparison of model performance
ggplot(results_long, aes(x = Mod√®le, y = Valeur, fill = Mod√®le)) +
geom_col(position = "dodge") +
facet_wrap(~ M√©trique, scales = "free_y") +
labs(
title = "Performances des mod√®les sur le jeu de test",
subtitle = "MAE, RMSE et R¬≤ compar√©s entre Lin√©aire, Ridge, Lasso et Elastic Net",
x = "Mod√®le",
y = "Valeur"
) +
theme_minimal() +
theme(legend.position = "none", text = element_text(size = 12))
# Mod√®le lin√©aire / Linear Model
lm_model <- lm(Gls ~ ., data = train_data %>% select(Gls, all_of(num_cols)))
lm_preds <- predict(lm_model, newdata = test_data)
lm_metrics <- data.frame(
Mod√®le = "Lin√©aire",
MAE = mae(y_test, lm_preds),
RMSE = rmse(y_test, lm_preds),
R2 = R2(lm_preds, y_test)
)
# Mod√®les p√©nalis√©s / Penalized models
ridge_metrics  <- eval_glmnet_model(X_train, y_train, X_test, y_test, alpha_val = 0, model_name = "Ridge")
lasso_metrics  <- eval_glmnet_model(X_train, y_train, X_test, y_test, alpha_val = 1, model_name = "Lasso")
elastic_metrics <- eval_glmnet_model(X_train, y_train, X_test, y_test, alpha_val = 0.5, model_name = "Elastic Net")
# On calcule les r√©sultats / We calculate the results
results <- bind_rows(lm_metrics, ridge_metrics, lasso_metrics, elastic_metrics)
print(results)
# Transformation en format long / Long format for plotting
results_long <- results %>%
pivot_longer(cols = c(MAE, RMSE, R2), names_to = "M√©trique", values_to = "Valeur")
# üìä Comparaison visuelle des mod√®les / Visual comparison of model performance
ggplot(results_long, aes(x = Mod√®le, y = Valeur, fill = Mod√®le)) +
geom_col(position = "dodge") +
facet_wrap(~ M√©trique, scales = "free_y") +
labs(
title = "Performances des mod√®les sur le jeu de test",
subtitle = "MAE, RMSE et R¬≤ compar√©s entre Lin√©aire, Ridge, Lasso et Elastic Net",
x = "Mod√®le",
y = "Valeur"
) +
theme_minimal() +
theme(legend.position = "none", text = element_text(size = 8))
# Mod√®le lin√©aire / Linear Model
lm_model <- lm(Gls ~ ., data = train_data %>% select(Gls, all_of(num_cols)))
lm_preds <- predict(lm_model, newdata = test_data)
lm_metrics <- data.frame(
Mod√®le = "Lin√©aire",
MAE = mae(y_test, lm_preds),
RMSE = rmse(y_test, lm_preds),
R2 = R2(lm_preds, y_test)
)
# Mod√®les p√©nalis√©s / Penalized models
ridge_metrics  <- eval_glmnet_model(X_train, y_train, X_test, y_test, alpha_val = 0, model_name = "Ridge")
lasso_metrics  <- eval_glmnet_model(X_train, y_train, X_test, y_test, alpha_val = 1, model_name = "Lasso")
elastic_metrics <- eval_glmnet_model(X_train, y_train, X_test, y_test, alpha_val = 0.5, model_name = "Elastic Net")
# On calcule les r√©sultats / We calculate the results
results <- bind_rows(lm_metrics, ridge_metrics, lasso_metrics, elastic_metrics)
print(results)
# üßæ Arrondir les m√©triques √† 2 chiffres / Round metrics to 2 decimals
results <- results %>%
mutate(across(c(MAE, RMSE, R2), ~ round(.x, 2)))
# Transformation en format long / Long format for plotting
results_long <- results %>%
pivot_longer(cols = c(MAE, RMSE, R2), names_to = "M√©trique", values_to = "Valeur")
# üìä Comparaison visuelle des mod√®les / Visual comparison of model performance
ggplot(results_long, aes(x = Mod√®le, y = Valeur, fill = Mod√®le)) +
geom_col(position = "dodge") +
facet_wrap(~ M√©trique, scales = "free_y") +
labs(
title = "Performances des mod√®les sur le jeu de test",
subtitle = "MAE, RMSE et R¬≤ compar√©s entre Lin√©aire, Ridge, Lasso et Elastic Net",
x = "Mod√®le",
y = "Valeur"
) +
theme_minimal() +
theme(legend.position = "none", text = element_text(size = 8))
#  Mod√®le lin√©aire / Linear Model
lm_model <- lm(Gls ~ ., data = train_data %>% select(Gls, all_of(num_cols)))
lm_preds <- predict(lm_model, newdata = test_data)
lm_metrics <- data.frame(
Mod√®le = "Lin√©aire",
MAE = mae(y_test, lm_preds),
RMSE = rmse(y_test, lm_preds),
R2 = R2(lm_preds, y_test)
)
#  Fonction d‚Äô√©valuation pour glmnet /  Evaluation function for glmnet
eval_glmnet_model <- function(X_train, y_train, X_test, y_test, alpha_val, model_name) {
set.seed(123)
cv_model <- cv.glmnet(X_train, y_train, alpha = alpha_val)
best_lambda <- cv_model$lambda.min
model <- glmnet(X_train, y_train, alpha = alpha_val, lambda = best_lambda)
preds <- predict(model, newx = X_test) %>% as.numeric()
data.frame(
Mod√®le = model_name,
MAE = mae(y_test, preds),
RMSE = rmse(y_test, preds),
R2 = R2(preds, y_test)
)
}
#  √âvaluation des mod√®les p√©nalis√©s / Penalized models
ridge_metrics   <- eval_glmnet_model(X_train, y_train, X_test, y_test, alpha_val = 0, model_name = "Ridge")
lasso_metrics   <- eval_glmnet_model(X_train, y_train, X_test, y_test, alpha_val = 1, model_name = "Lasso")
elastic_metrics <- eval_glmnet_model(X_train, y_train, X_test, y_test, alpha_val = 0.5, model_name = "Elastic Net")
# Regrouper les r√©sultats / Combine all results
results <- bind_rows(lm_metrics, ridge_metrics, lasso_metrics, elastic_metrics)
# Arrondir √† 2 d√©cimales / Round to 2 decimals
results <- results %>%
mutate(across(c(MAE, RMSE, R2), ~ round(.x, 2)))
# Format long pour ggplot / Long format for ggplot
results_long <- results %>%
pivot_longer(cols = c(MAE, RMSE, R2), names_to = "M√©trique", values_to = "Valeur")
# Comparaison graphique / Visual model performance comparison
ggplot(results_long, aes(x = Mod√®le, y = Valeur, fill = Mod√®le)) +
geom_col(position = "dodge") +
facet_wrap(~ M√©trique, scales = "free_y") +
labs(
title = "Performances des mod√®les sur le jeu de test / Model performance on the test set",
subtitle = "MAE, RMSE et R¬≤ compar√©s entre Lin√©aire, Ridge, Lasso et Elastic Net / MAE, RMSE and R¬≤ compared between Linear, Ridge, Lasso and Elastic Net",
x = "Mod√®le / Mod√®le",
y = "Valeur / Value"
) +
theme_minimal() +
theme(legend.position = "none", text = element_text(size = 8))
View(results)
View(results_long)
View(results)
# T√©l√©chargement des Librairies / Download libraries
library(tidymodels)
library(readr)
library(rmarkdown)
library(dplyr)
library(tidyr)
library(glmnet)
library(ggplot2)
library(Metrics)
library(caret)
# Chargement des donn√©es initiales contenant uniquement des donn√©es num√©riques
# Loading initial data containing only numerical data
data <- read_delim("dataset_24_25/players_data_light-2024_2025.csv", delim = ",")
# Nettoyage des noms de colonnes / Cleaning up column names
names(data) <- make.names(names(data), unique = TRUE)
# Exclure les gardiens / Exclude goalkeepers
data <- data %>% filter(Pos != "GK")
# Remplacer les NA dans les colonnes num√©riques par 0 / Replace NA in numeric columns with 0
data <- data %>%
mutate(across(where(is.numeric), ~replace_na(.x, 0)))
# Colonnes num√©riques √† utiliser sauf exclusions / Numerical columns to be used unless excluded
cols_to_exclude <- c("Rk", "Age", "Born", "G.A", "G.PK", "G.A.PK", "G.Sh", "G.xG","PK","np.G.xG", "G.SoT", "PK_stats_shooting")
num_cols <- data %>%
select(where(is.numeric)) %>%
select(-any_of(cols_to_exclude)) %>%
colnames()
# Cr√©er le jeu de donn√©es pour le mod√®le / Create the dataset for the model
data_model <- data %>%
select(Gls, all_of(num_cols)) %>%
filter(!is.na(Gls))
# Cr√©er le mod√®le / Create the model
model <- lm(Gls ~ ., data = data_model)
# Pr√©parer les donn√©es pour pr√©diction (m√™me structure que data_model sans Gls)
# Prediction for the entire dataset (same structure as data_model without Gls)
predict_data <- data %>% select(all_of(num_cols))
# Cr√©er un nouveau dataset avec les infos utiles + pr√©diction
# Create a new dataset with useful information + prediction
data_with_preds <- data %>%
mutate(Gls_pred_linear = predict(model, newdata = predict_data),     # Pr√©diction brute / Raw prediction
Gls_pred_linear = round(Gls_pred_linear, 2)) %>%                     # Pr√©diction arrondie / Rounded prediction
select(Player, Nation, Pos, Squad, Gls, Gls_pred_linear)                    # Colonnes √† conserver / Selected columns
# üëÄ Afficher les premi√®res lignes / Display first rows
head(data_with_preds)
add_glmnet_prediction <- function(data_with_preds, data, y_var, x_vars, alpha_val, pred_col_name, seed = 123) {
# Variable cible / Target variable
y <- data[[y_var]]
# Variables explicatives sous forme de matrice / Explanatory variables as matrix
X <- data %>% select(all_of(x_vars)) %>% as.matrix()
# S√©lection du lambda optimal par validation crois√©e / Cross-validation to find optimal lambda
set.seed(seed)  # Pour reproductibilit√© / For reproducibility
cv_model <- cv.glmnet(X, y, alpha = alpha_val)
# Lambda optimal / Optimal lambda
best_lambda <- cv_model$lambda.min
cat("Lambda optimal pour", pred_col_name, ":", best_lambda, "\n")
# R√©entra√Ænement du mod√®le avec le meilleur lambda / Retrain model with best lambda
best_model <- glmnet(X, y, alpha = alpha_val, lambda = best_lambda)
# Pr√©dictions sous forme de vecteur et arrondi / Predictions as numeric vector, rounded
predictions <- predict(best_model, newx = X) %>%
as.numeric() %>%
round(2)
# Ajout des pr√©dictions au dataset / Add predictions to the dataset
data_with_preds[[pred_col_name]] <- predictions
# Retourner le nouveau tableau enrichi / Return the updated dataset
return(data_with_preds)
}
# Ajouter les pr√©dictions Ridge / Add Ridge predictions
data_with_preds <- add_glmnet_prediction(
data_with_preds = data_with_preds,
data = data,
y_var = "Gls",              # Nom de la variable cible / Target variable name
x_vars = num_cols,          # Liste des variables explicatives / List of explanatory variables
alpha_val = 0,              # alpha = 0 ‚Üí Ridge
pred_col_name = "Gls_pred_ridge"
)
# Ajouter les pr√©dictions Lasso / Add Lasso predictions
data_with_preds <- add_glmnet_prediction(
data_with_preds,
data,
"Gls",
num_cols,
alpha_val = 1,              # alpha = 1 ‚Üí Lasso
pred_col_name = "Gls_pred_lasso"
)
# Ajouter les pr√©dictions Elastic Net / Add Elastic Net predictions
data_with_preds <- add_glmnet_prediction(
data_with_preds,
data,
"Gls",
num_cols,
alpha_val = 0.5,            # alpha = 0.5 ‚Üí Elastic Net (mix Ridge + Lasso)
pred_col_name = "Gls_pred_elastic"
)
# Afficher les premi√®res lignes / Display first rows
head(data_with_preds)
# Calcul des erreurs pour chaque mod√®le / Error calculation for each model
# Mod√®le lin√©aire / Linear Model
mae_linear <- mae(data_with_preds$Gls, data_with_preds$Gls_pred_linear)
rmse_linear <- rmse(data_with_preds$Gls, data_with_preds$Gls_pred_linear)
r2_linear <- R2(data_with_preds$Gls_pred_linear, data_with_preds$Gls)
# R√©gression Ridge / Ridge Regression
mae_ridge <- mae(data_with_preds$Gls, data_with_preds$Gls_pred_ridge)
rmse_ridge <- rmse(data_with_preds$Gls, data_with_preds$Gls_pred_ridge)
r2_ridge <- R2(data_with_preds$Gls_pred_ridge, data_with_preds$Gls)
# R√©gression Lasso / Lasso Regression
mae_lasso <- mae(data_with_preds$Gls, data_with_preds$Gls_pred_lasso)
rmse_lasso <- rmse(data_with_preds$Gls, data_with_preds$Gls_pred_lasso)
r2_lasso <- R2(data_with_preds$Gls_pred_lasso, data_with_preds$Gls)
# R√©gression Elastic Net / Elastic Net Regression
mae_elastic <- mae(data_with_preds$Gls, data_with_preds$Gls_pred_elastic)
rmse_elastic <- rmse(data_with_preds$Gls, data_with_preds$Gls_pred_elastic)
r2_elastic <- R2(data_with_preds$Gls_pred_elastic, data_with_preds$Gls)
# üßæ R√©sum√© des performances / Summary table
performance_comparison <- data.frame(
Mod√®le = c("Lin√©aire", "Ridge", "Lasso", "Elastic Net"),
MAE = c(mae_linear, mae_ridge, mae_lasso, mae_elastic),
RMSE = c(rmse_linear, rmse_ridge, rmse_lasso, rmse_elastic),
R2 = c(r2_linear, r2_ridge, r2_lasso, r2_elastic)
)
# Affichage du tableau de comparaison / Display comparison table
print(performance_comparison)
# R√©utiliser ou cr√©er le tableau de performances / Reuse or create the performance chart
performance_comparison <- data.frame(
Mod√®le = c("Lin√©aire", "Ridge", "Lasso", "Elastic Net"),
MAE = c(mae_linear, mae_ridge, mae_lasso, mae_elastic),
RMSE = c(rmse_linear, rmse_ridge, rmse_lasso, rmse_elastic),
R2 = c(r2_linear, r2_ridge, r2_lasso, r2_elastic)
)
# üìê Convertir en format long pour ggplot2 / Convert to long format for ggplot2
performance_long <- performance_comparison %>%
pivot_longer(cols = c(MAE, RMSE, R2), names_to = "M√©trique", values_to = "Valeur")
# Graphique comparatif / Comparative performance plot
ggplot(performance_long, aes(x = Mod√®le, y = Valeur, fill = Mod√®le)) +
geom_col(position = "dodge") +
facet_wrap(~ M√©trique, scales = "free_y") +
labs(title = "Comparaison des performances des mod√®les / Model performance comparison",
x = "Mod√®le / Models",
y = "Valeur de la m√©trique / Metric value") +
theme_minimal() +
theme(legend.position = "none",
text = element_text(size = 8))
set.seed(42)  # Reproductibilit√© / Reproducibility
train_index <- createDataPartition(data$Gls, p = 0.8, list = FALSE)
train_data <- data[train_index, ]
test_data  <- data[-train_index, ]
# Variables explicatives / Features matrix
X_train <- train_data %>% select(all_of(num_cols)) %>% as.matrix()
X_test  <- test_data %>% select(all_of(num_cols)) %>% as.matrix()
# Cible / Target
y_train <- train_data$Gls
y_test  <- test_data$Gls
eval_glmnet_model <- function(X_train, y_train, X_test, y_test, alpha_val, model_name) {
set.seed(123)
cv_model <- cv.glmnet(X_train, y_train, alpha = alpha_val)
best_lambda <- cv_model$lambda.min
model <- glmnet(X_train, y_train, alpha = alpha_val, lambda = best_lambda)
preds <- predict(model, newx = X_test) %>% as.numeric()
data.frame(
Mod√®le = model_name,
MAE = mae(y_test, preds),
RMSE = rmse(y_test, preds),
R2 = R2(preds, y_test)
)
}
#  Mod√®le lin√©aire / Linear Model
lm_model <- lm(Gls ~ ., data = train_data %>% select(Gls, all_of(num_cols)))
lm_preds <- predict(lm_model, newdata = test_data)
lm_metrics <- data.frame(
Mod√®le = "Lin√©aire",
MAE = mae(y_test, lm_preds),
RMSE = rmse(y_test, lm_preds),
R2 = R2(lm_preds, y_test)
)
#  Fonction d‚Äô√©valuation pour glmnet /  Evaluation function for glmnet
eval_glmnet_model <- function(X_train, y_train, X_test, y_test, alpha_val, model_name) {
set.seed(123)
cv_model <- cv.glmnet(X_train, y_train, alpha = alpha_val)
best_lambda <- cv_model$lambda.min
model <- glmnet(X_train, y_train, alpha = alpha_val, lambda = best_lambda)
preds <- predict(model, newx = X_test) %>% as.numeric()
data.frame(
Mod√®le = model_name,
MAE = mae(y_test, preds),
RMSE = rmse(y_test, preds),
R2 = R2(preds, y_test)
)
}
#  √âvaluation des mod√®les p√©nalis√©s / Penalized models
ridge_metrics   <- eval_glmnet_model(X_train, y_train, X_test, y_test, alpha_val = 0, model_name = "Ridge")
lasso_metrics   <- eval_glmnet_model(X_train, y_train, X_test, y_test, alpha_val = 1, model_name = "Lasso")
elastic_metrics <- eval_glmnet_model(X_train, y_train, X_test, y_test, alpha_val = 0.5, model_name = "Elastic Net")
# Regrouper les r√©sultats / Combine all results
results <- bind_rows(lm_metrics, ridge_metrics, lasso_metrics, elastic_metrics)
# Arrondir √† 2 d√©cimales / Round to 2 decimals
results <- results %>%
mutate(across(c(MAE, RMSE, R2), ~ round(.x, 2)))
# Format long pour ggplot / Long format for ggplot
results_long <- results %>%
pivot_longer(cols = c(MAE, RMSE, R2), names_to = "M√©trique", values_to = "Valeur")
# Comparaison graphique / Visual model performance comparison
ggplot(results_long, aes(x = Mod√®le, y = Valeur, fill = Mod√®le)) +
geom_col(position = "dodge") +
facet_wrap(~ M√©trique, scales = "free_y") +
labs(
title = "Performances des mod√®les sur le jeu de test / Model performance on the test set",
subtitle = "MAE, RMSE et R¬≤ compar√©s entre Lin√©aire, Ridge, Lasso et Elastic Net / MAE, RMSE and R¬≤ compared between Linear, Ridge, Lasso and Elastic Net",
x = "Mod√®le / Mod√®le",
y = "Valeur / Value"
) +
theme_minimal() +
theme(legend.position = "none", text = element_text(size = 8))
