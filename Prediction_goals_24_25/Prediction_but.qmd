---
title: "Prediction du nombre de buts inscrit par joueur / Prediction of the number of goals scored per player"
format: 
  pdf:
    toc: true
    number-sections: false
editor: source
---

## Introduction : Pr√©sentation du jeu de donn√©es et du sujet / Introducing the dataset and the subject

Cet ensemble de donn√©es contient les statistiques des joueurs de la saison 2024-2025 dans les cinq principaux championnats europ√©ens, provenant de FBref. / This dataset features player statistics from the 2024-2025 season across the top five European leagues, sourced from FBref.

Veuillez trouver ci-dessous la description des colonnes de ce jeu de donn√©es regroup√©es par cat√©gorie / Please find below a description of the columns in this dataset grouped by category :

-   Information de base par joueur / Basic Player Information

`Player`‚Äì Nom du joueur / Player's name, `Nation` ‚Äì Nationalit√© du joueur / Player's nationality, `Pos` ‚Äì Position / Position (FW, MF, DF, GK), `Squad` ‚Äì Nom du club / Club name, `Comp` ‚Äì Championnat / League, `Age` ‚Äì √Çge du joueur / Age of the player, `Born` ‚Äì Ann√©e de naissance / Year of birth

-   Temps de jeu et apparitions / Playing time and Appearances

`MP` ‚Äì Matches jou√©es / Matches played, `Starts` ‚Äì Parties commenc√©es / Games started, `Min` ‚Äì Minutes jou√©es / Minutes played, `90s` ‚Äì Nombre de matchs jou√©es en entier / Number of full 90-minute matches played

-   Stats offensives / Attacking stats

`Gls` ‚Äì Buts marqu√©es / Goals scored, `Ast` ‚Äì Passes d√©cisives apport√©es / Assists provided, `G+A` ‚Äì Buts + Passes d√©cisives / Goals + Assists, `xG` ‚Äì Buts Attendus / Expected goals\
`xAG` ‚Äì Passes d√©cisives attendus / Expected assists, `npxG` ‚ÄìButs attendus sans les penaltys / Non-penalty expected goals, `G-PK` ‚Äì Buts saufs penaltys / Goals excluding penalties

-   Stats d√©fensives / Defensive stats

`Tkl` ‚Äì Total de tacles / Total tackles, `TklW` ‚Äì Tacles gagn√©s /Tackles won, `Blocks` ‚Äì Blocs r√©alis√©es / Blocks made, `Int` ‚Äì Interceptions / Interceptions, `Tkl+Int` ‚Äì Tacles et interceptions combin√©s / Combined tackles and interceptions, `Clr` ‚Äì D√©gagements / Clearances, `Err` ‚Äì Erreurs menant √† un but / Errors leading to goals

-   Stats de passes et de cr√©ativit√© / Passing and Creativity stats

`PrgP` ‚Äì Passes progressive / Progressive passes, `PrgC` ‚Äì Phase de portage du ballon progressive / Progressive carries, `KP` ‚Äì Passes cl√©s (passes menant √† un tir) / Key passes (passes leading to a shot), `Cmp%_stats_passing` ‚Äì Pourcentage de passes r√©ussis / Pass completion percentage, `Ast_stats_passing` ‚Äì Passes d√©cisives / Assists, `xA` ‚Äì Passes d√©cisives attendus / Expected assists, `PPA` ‚Äì Passes dans la surface de r√©paration / Passes into the penalty area

-   Stats du gardien / Goalkeeping stats

`GA` ‚Äì Buts conc√©d√©s / Goals conceded, `Saves` ‚Äì Arr√™ts effectu√©s / Saves made, `Save%` ‚Äì Pourcentage d'arr√™t / Save percentage, `CS` ‚Äì Pas de buts pris dans le match / Clean sheets\
`CS%` ‚Äì Pourcentage de matchs sans buts encaiss√©s / Clean sheet percentage, `PKA` ‚Äì Penaltys rencontr√©s / Penalties faced, `PKsv` ‚Äì Penalties arr√©t√©s / Penalty saves

-   Possession et Contr√¥le du ballon / Possession and Ball control

`Touches` ‚Äì Total de touches de balles / Total touches of the ball, `Carries` ‚Äì Total de ballon port√©s / Total ball carries, `PrgR` ‚Äì Courses progressive (en portant le ballon vers l'avant de fa√ßon significative) / Progressive runs (carries moving the ball forward significantly), `Mis` ‚Äì Mauvais contr√¥le du ballon / Miscontrols, `Dis` ‚Äì Perte du ballon / Times dispossessed

-   Statistiques diverses / Miscellaneous stats

`CrdY` ‚Äì Cartons jaunes / Yellow cards, `CrdR` ‚Äì Carton rouge / Red cards, `PKwon` ‚Äì Penalties gagn√©es / Penalties won, `PKcon` ‚Äì Penalties conc√©d√©s / Penalties conceded, `Recov` ‚Äì Ballon r√©cup√©r√©s / Ball recoveries

On va dans un 1er temps importer les librairies puis les donn√©es. / First, we'll import the libraries, then the data.

```{r,include=FALSE}
# Installation des packages / Install packages
#install.packages("tidymodels")
#install.packages("readr")
#install.packages("rmarkdown")
#install.packages("dplyr")
#install.packages("tidyr")
#install.packages("glmnet")
#install.packages("ggplot2")
#install.packages("Metrics")
#install.packages("caret")
```

```{r setup ,include=FALSE}
# T√©l√©chargement des Librairies / Download libraries
library(tidymodels)
library(readr)
library(rmarkdown)
library(dplyr)
library(tidyr)
library(glmnet)
library(ggplot2)
library(Metrics)
library(caret)
```

```{r,include=FALSE}
# Chargement des donn√©es initiales contenant uniquement des donn√©es num√©riques
# Loading initial data containing only numerical data
data <- read_delim("dataset_24_25/players_data_light-2024_2025.csv", delim = ",")

```

On va ensuite pr√©dire le nombre de buts inscrits par joueur / We will then predict the number of goals scored per player.

## Traitement des donn√©es / Data processing

```{r}
# Nettoyage des noms de colonnes / Cleaning up column names
names(data) <- make.names(names(data), unique = TRUE)

# Exclure les gardiens / Exclude goalkeepers
data <- data %>% filter(Pos != "GK")

# Remplacer les NA dans les colonnes num√©riques par 0 / Replace NA in numeric columns 
# with 0
data <- data %>%
  mutate(across(where(is.numeric), ~replace_na(.x, 0)))

# Colonnes num√©riques √† utiliser sauf exclusions / Numerical columns to be
# used unless excluded
cols_to_exclude <- c("Rk", "Age", "Born", "G.A", "G.PK", "G.A.PK", "G.Sh",
                     "G.xG","PK","np.G.xG", "G.SoT", "PK_stats_shooting")
num_cols <- data %>%
  select(where(is.numeric)) %>%
  select(-any_of(cols_to_exclude)) %>%
  colnames()
```


## M√©thode : Mod√®les de r√©gression lin√©aire / Method : Linear regression models

```{r}
# Cr√©er le jeu de donn√©es pour le mod√®le / Create the dataset for the model
data_model <- data %>%
  select(Gls, all_of(num_cols)) %>%
  filter(!is.na(Gls))

# Cr√©er le mod√®le / Create the model
model <- lm(Gls ~ ., data = data_model)

# Pr√©parer les donn√©es pour pr√©diction (m√™me structure que data_model sans Gls)
# Prediction for the entire dataset (same structure as data_model without Gls)
predict_data <- data %>% select(all_of(num_cols))

# Cr√©er un nouveau dataset avec les infos utiles + pr√©diction
# Create a new dataset with useful information + prediction
data_with_preds <- data %>%
  mutate(Gls_pred_linear = predict(model, newdata = predict_data),
         Gls_pred_linear = round(Gls_pred_linear, 2)) %>%
  select(Player, Nation, Pos, Squad, Gls, Gls_pred_linear)

# Afficher les premi√®res lignes / Display first rows
head(data_with_preds)
```

Interpr√©tation : Le mod√®le a une capacit√© de pr√©diction satisfaisant comme le montre le R\^2 ajust√© de 0.90. Des variables significatives semblent se d√©gager comme le nombre de tirs cadr√©s (SoT : 0.23), celui du total des penalties obtenus (PKWon : -0.16) et le nombre de passes d√©cisives (Ast : -0.14). N√©anmoins, certaines variables semblent fortement li√©es entre elles ce qui peut biaiser la pr√©diction du mod√®le. De plus, un nombre important de variable semblent non significatives. De ce fait, on va tester des mod√®les plus adapt√©s dans la r√©gularisation de ce type de donn√©es afin d'observer si ces algorithmes sont plus efficaces.

Interpretation: The model has a satisfactory predictive capacity, as shown by the adjusted R\^2 of 0.90. Significant variables seem to emerge, such as the number of shots on target (SoT: 0.23), total penalties won (PKWon: -0.16) and the number of assists (Ast: -0.14). Nevertheless, some variables appear to be strongly interrelated, which may bias the model's prediction. In addition, a significant number of variables appear to be insignificant. As a result, we'll be testing more suitable models for regularizing this type of data, to see whether.

## M√©thode : Mod√®les de r√©gression lin√©aire r√©gularis√©e / Method : Regularized linear regression models

On va cr√©er un fonction pour les 3 types de mod√®le de r√©gression r√©gularis√©e : Ridge, Lasso, Elastic Net. / We will create a function for the 3 types of regularized regression models: Ridge, Lasso, Elastic Net.

```{r}
add_glmnet_prediction <- function(data_with_preds, data, y_var, x_vars,
                                  alpha_val, pred_col_name, seed = 123) {

  # Variable cible / Target variable
  y <- data[[y_var]]

  # Variables explicatives sous forme de matrice
  # Explanatory variables as matrix
  X <- data %>% select(all_of(x_vars)) %>% as.matrix()

  # S√©lection du lambda optimal par validation crois√©e
  # Cross-validation to find optimal lambda
  set.seed(seed)  # Pour reproductibilit√© / For reproducibility
  cv_model <- cv.glmnet(X, y, alpha = alpha_val)

  # Lambda optimal / Optimal lambda
  best_lambda <- cv_model$lambda.min
  cat("Lambda optimal pour", pred_col_name, ":", best_lambda, "\n")

  # R√©entra√Ænement du mod√®le avec le meilleur lambda
  # Retrain model with best lambda
  best_model <- glmnet(X, y, alpha = alpha_val, lambda = best_lambda)

  # Pr√©dictions sous forme de vecteur et arrondi
  # Predictions as numeric vector, rounded
  predictions <- predict(best_model, newx = X) %>%
    as.numeric() %>%
    round(2)

  # Ajout des pr√©dictions au dataset / Add predictions to the dataset
  data_with_preds[[pred_col_name]] <- predictions

  # Retourner le nouveau tableau enrichi / Return the updated dataset
  return(data_with_preds)
}

```

On va ensuite effectuer ces pr√©dictions. / We will then make these predictions.

```{r}
# Ajouter les pr√©dictions Ridge / Add Ridge predictions
data_with_preds <- add_glmnet_prediction(
  data_with_preds = data_with_preds,
  data = data,
  y_var = "Gls",
  x_vars = num_cols, 
  alpha_val = 0,              # alpha = 0 ‚Üí Ridge
  pred_col_name = "Gls_pred_ridge"
)

# Ajouter les pr√©dictions Lasso / Add Lasso predictions
data_with_preds <- add_glmnet_prediction(
  data_with_preds,
  data,
  "Gls",
  num_cols,
  alpha_val = 1,              # alpha = 1 ‚Üí Lasso
  pred_col_name = "Gls_pred_lasso"
)

# Ajouter les pr√©dictions Elastic Net / Add Elastic Net predictions
data_with_preds <- add_glmnet_prediction(
  data_with_preds,
  data,
  "Gls",
  num_cols,
  alpha_val = 0.5,            # alpha = 0.5 ‚Üí Elastic Net (mix Ridge + Lasso)
  pred_col_name = "Gls_pred_elastic"
)

# Afficher les premi√®res lignes / Display first rows
head(data_with_preds)

```

Interpr√©tation : Les valeurs de lambda optimales indiquent une r√©gularisation mod√©r√©e : Ridge applique une r√©duction g√©n√©rale des coefficients, tandis que Lasso et Elastic Net utilisent une p√©nalisation plus l√©g√®re, sugg√©rant peu de variables redondantes et un faible risque de surapprentissage.

Interpretation : Optimal lambda values indicate moderate regularization: Ridge applies a general reduction in coefficients, while Lasso and Elastic Net use lighter penalization, suggesting few redundant variables and a low risk of overlearning.


## Comparatif / Comparative

    ```{r}
    # Calcul des erreurs pour chaque mod√®le / Error calculation for each model

    # Mod√®le lin√©aire / Linear Model
    mae_linear <- mae(data_with_preds$Gls, data_with_preds$Gls_pred_linear)
    rmse_linear <- rmse(data_with_preds$Gls, data_with_preds$Gls_pred_linear)
    r2_linear <- R2(data_with_preds$Gls_pred_linear, data_with_preds$Gls)

    # R√©gression Ridge / Ridge Regression
    mae_ridge <- mae(data_with_preds$Gls, data_with_preds$Gls_pred_ridge)
    rmse_ridge <- rmse(data_with_preds$Gls, data_with_preds$Gls_pred_ridge)
    r2_ridge <- R2(data_with_preds$Gls_pred_ridge, data_with_preds$Gls)

    # R√©gression Lasso / Lasso Regression
    mae_lasso <- mae(data_with_preds$Gls, data_with_preds$Gls_pred_lasso)
    rmse_lasso <- rmse(data_with_preds$Gls, data_with_preds$Gls_pred_lasso)
    r2_lasso <- R2(data_with_preds$Gls_pred_lasso, data_with_preds$Gls)

    # R√©gression Elastic Net / Elastic Net Regression
    mae_elastic <- mae(data_with_preds$Gls, data_with_preds$Gls_pred_elastic)
    rmse_elastic <- rmse(data_with_preds$Gls, data_with_preds$Gls_pred_elastic)
    r2_elastic <- R2(data_with_preds$Gls_pred_elastic, data_with_preds$Gls)

    # üßæ R√©sum√© des performances / Summary table
    performance_comparison <- data.frame(
      Mod√®le = c("Lin√©aire", "Ridge", "Lasso", "Elastic Net"),
      MAE = c(mae_linear, mae_ridge, mae_lasso, mae_elastic),
      RMSE = c(rmse_linear, rmse_ridge, rmse_lasso, rmse_elastic),
      R2 = c(r2_linear, r2_ridge, r2_lasso, r2_elastic)
    )

    # Affichage du tableau de comparaison / Display comparison table
    print(performance_comparison)

    # R√©utiliser ou cr√©er le tableau de performances / Reuse or create the performance chart
    performance_comparison <- data.frame(
      Mod√®le = c("Lin√©aire", "Ridge", "Lasso", "Elastic Net"),
      MAE = c(mae_linear, mae_ridge, mae_lasso, mae_elastic),
      RMSE = c(rmse_linear, rmse_ridge, rmse_lasso, rmse_elastic),
      R2 = c(r2_linear, r2_ridge, r2_lasso, r2_elastic)
    )

    # üìê Convertir en format long pour ggplot2 / Convert to long format for ggplot2
    performance_long <- performance_comparison %>%
      pivot_longer(cols = c(MAE, RMSE, R2), names_to = "M√©trique", values_to = "Valeur")

    # Graphique comparatif / Comparative performance plot
    ggplot(performance_long, aes(x = Mod√®le, y = Valeur, fill = Mod√®le)) +
      geom_col(position = "dodge") +
      facet_wrap(~ M√©trique, scales = "free_y") +
      labs(title = "Comparaison des performances des mod√®les / Model performance comparison",
           x = "Mod√®le / Models",
           y = "Valeur de la m√©trique / Metric value") +
      theme_minimal() +
      theme(legend.position = "none",
            text = element_text(size = 8))
    ```

Interpr√©tation : Les mod√®les Lasso et Elastic Net offrent les meilleures performances, avec des erreurs tr√®s faibles (MAE \< 0.06, RMSE \< 0.1) et un R¬≤ quasi parfait, indiquant un excellent pouvoir pr√©dictif. Le mod√®le Ridge est √©galement performant, tandis que le mod√®le lin√©aire est nettement moins pr√©cis. N√©anmoins, les performances tr√®s √©lev√©es de Lasso et Elastic Net sugg√®rent un possible surapprentissage. Une validation sur un jeu de test s√©par√© est n√©cessaire pour confirmer leur capacit√© de g√©n√©ralisation.

Interpretation : The Lasso and Elastic Net models offer the best performance, with very low errors (MAE \< 0.06, RMSE \< 0.1) and near-perfect R¬≤, indicating excellent predictive power. The Ridge model also performs well, while the linear model is considerably less accurate. Nevertheless, the very high performance of Lasso and Elastic Net suggests possible overlearning. Validation on a separate test set is required to confirm their generalizability.

5.  Validation crois√©e / Cross-validation

On va d'abord s√©parer les donn√©es en jeu d'entrainement et test (80/20). / First, we'll separate the data into training and test sets (80/20).

```{r}
set.seed(42)  # Reproductibilit√© / Reproducibility
train_index <- createDataPartition(data$Gls, p = 0.8, list = FALSE)

train_data <- data[train_index, ]
test_data  <- data[-train_index, ]

# Variables explicatives / Features matrix
X_train <- train_data %>% select(all_of(num_cols)) %>% as.matrix()
X_test  <- test_data %>% select(all_of(num_cols)) %>% as.matrix()

# Cible / Target
y_train <- train_data$Gls
y_test  <- test_data$Gls

```

On va ensuite cr√©er un fonction d'√©valuation de ces mod√®les. / We'll then create an evaluation function for these models.

```{r}
eval_glmnet_model <- function(X_train, y_train, X_test,
                              y_test, alpha_val, model_name) {
  set.seed(123)
  cv_model <- cv.glmnet(X_train, y_train, alpha = alpha_val)
  best_lambda <- cv_model$lambda.min

  model <- glmnet(X_train, y_train, alpha = alpha_val, lambda = best_lambda)
  preds <- predict(model, newx = X_test) %>% as.numeric()

  data.frame(
    Mod√®le = model_name,
    MAE = mae(y_test, preds),
    RMSE = rmse(y_test, preds),
    R2 = R2(preds, y_test)
  )
}

```

On va logiquement les √©valuer par la suite. / We will then logically evaluate them.

```{r}
#  Mod√®le lin√©aire / Linear Model
lm_model <- lm(Gls ~ ., data = train_data %>% select(Gls, all_of(num_cols)))
lm_preds <- predict(lm_model, newdata = test_data)
lm_metrics <- data.frame(
  Mod√®le = "Lin√©aire",
  MAE = mae(y_test, lm_preds),
  RMSE = rmse(y_test, lm_preds),
  R2 = R2(lm_preds, y_test)
)

#  Fonction d‚Äô√©valuation pour glmnet /  Evaluation function for glmnet
eval_glmnet_model <- function(X_train, y_train, X_test, 
                              y_test, alpha_val, model_name) {
  set.seed(123)
  cv_model <- cv.glmnet(X_train, y_train, alpha = alpha_val)
  best_lambda <- cv_model$lambda.min
  model <- glmnet(X_train, y_train, alpha = alpha_val, lambda = best_lambda)
  preds <- predict(model, newx = X_test) %>% as.numeric()
  
  data.frame(
    Mod√®le = model_name,
    MAE = mae(y_test, preds),
    RMSE = rmse(y_test, preds),
    R2 = R2(preds, y_test)
  )
}

#  √âvaluation des mod√®les p√©nalis√©s / Penalized models
ridge_metrics   <- eval_glmnet_model(X_train, y_train, 
                                     X_test, y_test, alpha_val = 0,
                                     model_name = "Ridge")
lasso_metrics   <- eval_glmnet_model(X_train, y_train, 
                                     X_test, y_test, alpha_val = 1,
                                     model_name = "Lasso")
elastic_metrics <- eval_glmnet_model(X_train, y_train, 
                                     X_test, y_test, alpha_val = 0.5,
                                     model_name = "Elastic Net")

# Regrouper les r√©sultats / Combine all results
results <- bind_rows(lm_metrics, ridge_metrics, lasso_metrics, elastic_metrics)

# Arrondir √† 2 d√©cimales / Round to 2 decimals
results <- results %>%
  mutate(across(c(MAE, RMSE, R2), ~ round(.x, 2)))

# Format long pour ggplot / Long format for ggplot
results_long <- results %>%
  pivot_longer(cols = c(MAE, RMSE, R2),
               names_to = "M√©trique", values_to = "Valeur")

# Comparaison graphique / Visual model performance comparison
ggplot(results_long, aes(x = Mod√®le, y = Valeur, fill = Mod√®le)) +
  geom_col(position = "dodge") +
  facet_wrap(~ M√©trique, scales = "free_y") +
  labs(
    title = "Model performance on the test set",
    subtitle = "MAE, RMSE and R¬≤ compared between Linear, Ridge, Lasso and Elastic Net",
    x = "Mod√®le / Mod√®le",
    y = "Valeur / Value"
  ) +
  theme_minimal() +
  theme(legend.position = "none", text = element_text(size = 8))
```

## Conclusion

Les mod√®les r√©gularis√©s, notamment Lasso et Elastic Net, pr√©sentent des performances nettement sup√©rieures au mod√®le lin√©aire, avec une erreur minimale et un R¬≤ ‚âà 1 sur le jeu de test. Bien que ces r√©sultats aient √©t√© obtenus apr√®s validation crois√©e et test ind√©pendant, ce qui limite le risque de surapprentissage. N√©anmoins, leur pr√©cision quasi parfaite invite √† rester prudent. Ces mod√®les apparaissent toutefois comme les plus adapt√©s pour ce jeu de donn√©es, gr√¢ce √† leur capacit√© √† r√©gulariser efficacement sans perte de performance. 

Regularised models, notably Lasso and Elastic Net, performed significantly better than the linear model, achieving minimal error and an R¬≤ value of approximately 1 on the test set. These results were obtained after cross-validation and independent testing, which limits the risk of overlearning. Nevertheless, their near-perfect accuracy invites caution. These models appear to be the most suitable for this dataset thanks to their ability to regularise efficiently without loss of performance.
